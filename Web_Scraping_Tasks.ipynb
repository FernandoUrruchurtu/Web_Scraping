{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve 25 quotes, we have to move into pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving into pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_list = []\n",
    "for i in range(1,4):\n",
    "    print('page ', i)\n",
    "    resp = rq.get(f'http://quotes.toscrape.com/page/{i}')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    quotes = soup.find_all(\"span\", class_ = \"text\")\n",
    "    q = [quote.get_text() for quote in quotes]\n",
    "    quotes_list = quotes_list + q\n",
    "\n",
    "len(quotes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "for i in quotes_list:\n",
    "    print(f'{j} - {i}')\n",
    "    j += 1\n",
    "    if j == 26:\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_list = []\n",
    "for i in range(1,4):\n",
    "    print('page ', i)\n",
    "    resp = rq.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    books = soup.find_all(\"h3\")\n",
    "    bs = [book.find('a')['title'] for book in books]\n",
    "    books_list = books_list + bs\n",
    "\n",
    "len(books_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "for i in books_list:\n",
    "    print(f'{j} - {i}')\n",
    "    j += 1\n",
    "    if j == 51:\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLUS: Retrieving information from 50 books and saving into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_info(route:str) -> dict:\n",
    "    response = rq.get(f'http://books.toscrape.com/catalogue/{route}')\n",
    "    soups = BeautifulSoup(response.content, 'html.parser')\n",
    "    info_dict = {\n",
    "        \"title\":soups.find(\"h1\").get_text(),\n",
    "        \"description\":soups.find_all(\"p\")[3].get_text(),\n",
    "        \"image\":'http://books.toscrape.com'+soups.find(\"img\")['src'].replace('../..',''),\n",
    "        \"UPC\":((soups.find(\"table\", class_ = \"table table-striped\")).find_all(\"td\")[0]).get_text(),\n",
    "        \"price\":((soups.find(\"table\", class_ = \"table table-striped\")).find_all(\"td\")[2]).get_text()\n",
    "    }\n",
    "    return info_dict\n",
    "\n",
    "books_list_titles = []\n",
    "for i in range(1,4):\n",
    "    print('page ', i)\n",
    "    resp = rq.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    books = soup.find_all(\"h3\")\n",
    "    bs = [book.find('a')['href'] for book in books]\n",
    "    books_list_titles = books_list_titles + bs\n",
    "\n",
    "print(books_list_titles[0])\n",
    "\n",
    "dict_info = {\n",
    "        \"title\":[],\n",
    "        \"description\":[],\n",
    "        \"image\":[],\n",
    "        \"UPC\":[],\n",
    "        \"price\":[]\n",
    "}\n",
    "\n",
    "j = 0\n",
    "for i in books_list_titles:\n",
    "    data = get_book_info(route=i)\n",
    "    for key in dict_info:\n",
    "        dict_info[key].append(data[key])\n",
    "    j += 1\n",
    "    if j == 51:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "dict_info['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.DataFrame.from_dict(dict_info)\n",
    "df_books['image'].head(10)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.to_csv('books_scrapped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing but with xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Quotes (XPath version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page  1\n",
      "page  2\n",
      "page  3\n"
     ]
    }
   ],
   "source": [
    "quotes_list = []\n",
    "for i in range(1,4):\n",
    "    print('page ', i)\n",
    "    resp = rq.get(f'http://quotes.toscrape.com/page/{i}')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    x = etree.HTML(str(soup))\n",
    "    quotes = x.xpath('//div[@class=\"quote\"]/span[@class=\"text\"]/text()')\n",
    "    #<div class = \"quote\">\n",
    "    #   <span class = \"text\">Texto</span>\n",
    "    # </div>\n",
    "    #q = [quote.get_text() for quote in quotes]\n",
    "    quotes_list = quotes_list + quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“For every minute you are angry you lose sixty seconds of happiness.”\n"
     ]
    }
   ],
   "source": [
    "print(quotes_list[randint(14, 29)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Books (XPath Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = rq.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "x = etree.HTML(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page  1\n",
      "page  2\n",
      "page  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_list = []\n",
    "for i in range(1,4):\n",
    "    print('page ', i)\n",
    "    resp = rq.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    x = etree.HTML(str(soup))\n",
    "    books = x.xpath('//h3/a/@title')\n",
    "    books_list = books_list + books\n",
    "\n",
    "books_list[randint(0,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_list[randint(0,29)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLUS: Retrieving information from 50 books and saving into a CSV (XPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_info_xpath(route:str) -> dict:\n",
    "    response = rq.get(f'http://books.toscrape.com/catalogue/{route}')\n",
    "    soups = BeautifulSoup(response.content, 'html.parser')\n",
    "    x = etree.HTML(str(soups))\n",
    "    info_dict = {\n",
    "        \"title\":x.xpath('//h1/text()')[0],\n",
    "        \"description\":x.xpath(\"//div[@id='product_description']/following-sibling::p/text()\")[0],\n",
    "        \"image\":'http://books.toscrape.com'+x.xpath('//div[@class=\"item active\"]/img/@src')[0].replace('../..',''),\n",
    "        \"UPC\":x.xpath('//table[@class=\"table table-striped\"]//tr/td/text()')[0],\n",
    "        \"price\":x.xpath('//table[@class=\"table table-striped\"]//tr/td/text()')[2]\n",
    "    }\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page  1\n",
      "page  2\n",
      "page  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A Light in the Attic',\n",
       " 'Tipping the Velvet',\n",
       " 'Soumission',\n",
       " 'Sharp Objects',\n",
       " 'Sapiens: A Brief History of Humankind',\n",
       " 'The Requiem Red',\n",
       " 'The Dirty Little Secrets of Getting Your Dream Job',\n",
       " 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull',\n",
       " 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics',\n",
       " 'The Black Maria',\n",
       " 'Starving Hearts (Triangular Trade Trilogy, #1)',\n",
       " \"Shakespeare's Sonnets\",\n",
       " 'Set Me Free',\n",
       " \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\",\n",
       " 'Rip it Up and Start Again',\n",
       " 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991',\n",
       " 'Olio',\n",
       " 'Mesaerion: The Best Science Fiction Stories 1800-1849',\n",
       " 'Libertarianism for Beginners',\n",
       " \"It's Only the Himalayas\",\n",
       " 'In Her Wake',\n",
       " 'How Music Works',\n",
       " 'Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More',\n",
       " 'Chase Me (Paris Nights #2)',\n",
       " 'Black Dust',\n",
       " 'Birdsong: A Story in Pictures',\n",
       " \"America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana\",\n",
       " 'Aladdin and His Wonderful Lamp',\n",
       " 'Worlds Elsewhere: Journeys Around Shakespeare’s Globe',\n",
       " 'Wall and Piece',\n",
       " 'The Four Agreements: A Practical Guide to Personal Freedom',\n",
       " 'The Five Love Languages: How to Express Heartfelt Commitment to Your Mate',\n",
       " 'The Elephant Tree',\n",
       " 'The Bear and the Piano',\n",
       " \"Sophie's World\",\n",
       " 'Penny Maybe',\n",
       " 'Maude (1883-1993):She Grew Up with the country',\n",
       " 'In a Dark, Dark Wood',\n",
       " 'Behind Closed Doors',\n",
       " \"You can't bury them all: Poems\",\n",
       " 'Slow States of Collapse: Poems',\n",
       " 'Reasons to Stay Alive',\n",
       " 'Private Paris (Private #10)',\n",
       " '#HigherSelfie: Wake Up Your Life. Free Your Soul. Find Your Tribe.',\n",
       " 'Without Borders (Wanderlove #1)',\n",
       " 'When We Collided',\n",
       " 'We Love You, Charlie Freeman',\n",
       " 'Untitled Collection: Sabbath Poems 2014',\n",
       " 'Unseen City: The Majesty of Pigeons, the Discreet Charm of Snails & Other Wonders of the Urban Wilderness',\n",
       " 'Unicorn Tracks',\n",
       " 'Unbound: How Eight Technologies Made Us Human, Transformed Society, and Brought Our World to the Brink']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_list = []\n",
    "for i in range(1,4):\n",
    "    resp = rq.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    x = etree.HTML(str(soup))\n",
    "    books = x.xpath('//h3/a/@href')\n",
    "    books_list = books_list + books\n",
    "\n",
    "dict_info = {\n",
    "        \"title\":[],\n",
    "        \"description\":[],\n",
    "        \"image\":[],\n",
    "        \"UPC\":[],\n",
    "        \"price\":[]\n",
    "}\n",
    "\n",
    "j = 0\n",
    "for i in books_list:\n",
    "    data = get_book_info_xpath(route=i)\n",
    "    for key in dict_info:\n",
    "        dict_info[key].append(data[key])\n",
    "    j += 1\n",
    "    if j == 51:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "dict_info['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prove = 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "response = rq.get(url_prove)\n",
    "soups = BeautifulSoup(response.content, 'html.parser')\n",
    "x = etree.HTML(str(soups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.DataFrame.from_dict(dict_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>image</th>\n",
       "      <th>UPC</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>It's hard to imagine a world without A Light i...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/fe/72/fe...</td>\n",
       "      <td>a897fe39b1053632</td>\n",
       "      <td>£51.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>\"Erotic and absorbing...Written with starling ...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/08/e9/08...</td>\n",
       "      <td>90fa61229261140a</td>\n",
       "      <td>£53.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>Dans une France assez proche de la nôtre, un h...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/ee/cf/ee...</td>\n",
       "      <td>6957f44c3847a760</td>\n",
       "      <td>£50.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/c0/59/c0...</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "      <td>£47.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>From a renowned historian comes a groundbreaki...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/ce/5f/ce...</td>\n",
       "      <td>4165285e1663650f</td>\n",
       "      <td>£54.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                   A Light in the Attic   \n",
       "1                     Tipping the Velvet   \n",
       "2                             Soumission   \n",
       "3                          Sharp Objects   \n",
       "4  Sapiens: A Brief History of Humankind   \n",
       "\n",
       "                                         description  \\\n",
       "0  It's hard to imagine a world without A Light i...   \n",
       "1  \"Erotic and absorbing...Written with starling ...   \n",
       "2  Dans une France assez proche de la nôtre, un h...   \n",
       "3  WICKED above her hipbone, GIRL across her hear...   \n",
       "4  From a renowned historian comes a groundbreaki...   \n",
       "\n",
       "                                               image               UPC   price  \n",
       "0  http://books.toscrape.com/media/cache/fe/72/fe...  a897fe39b1053632  £51.77  \n",
       "1  http://books.toscrape.com/media/cache/08/e9/08...  90fa61229261140a  £53.74  \n",
       "2  http://books.toscrape.com/media/cache/ee/cf/ee...  6957f44c3847a760  £50.10  \n",
       "3  http://books.toscrape.com/media/cache/c0/59/c0...  e00eb4fd7b871a48  £47.82  \n",
       "4  http://books.toscrape.com/media/cache/ce/5f/ce...  4165285e1663650f  £54.23  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.to_csv('books_scrapped_xpath.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=df_books['image'][randint(13,38)], width=250, height=250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
